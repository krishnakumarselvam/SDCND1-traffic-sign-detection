{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model diagnostics and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "# Load up the augmented training datasign_names = pd.read_csv('signnames.csv')\n",
    "validation_file='../data/valid.p'\n",
    "testing_file = '../data/test.p'\n",
    "\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "sign_names = pd.read_csv('signnames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.layers import flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "def flatten_conv(x, input_shape, output_len):\n",
    "    if input_shape[0] * input_shape[1] * input_shape[2] - output_len:\n",
    "        raise Exception('Input and output shape mismatch while flattening')\n",
    "    return flatten(x)\n",
    "\n",
    "def fc_relu(x, input_len, output_len):\n",
    "    _fc = fc(x, input_len, output_len)\n",
    "    return  tf.nn.relu(_fc)\n",
    "\n",
    "def fc(x, input_len, output_len):\n",
    "    fc_W  = tf.Variable(tf.truncated_normal(shape=(input_len, output_len), mean = mu, stddev = sigma))\n",
    "    fc_b  = tf.Variable(tf.zeros(output_len))\n",
    "    _fc    = tf.matmul(x, fc_W) + fc_b\n",
    "    return _fc\n",
    "\n",
    "def max_pool(x, input_shape, output_shape, kernel_width=2, stride=2):\n",
    "    input_width = input_shape[0]\n",
    "    output_width = output_shape[0]\n",
    "    if input_width/2 == output_width:\n",
    "        return tf.nn.max_pool(x, ksize=[1, kernel_width, kernel_width, 1], strides=[1, stride, stride, 1], padding='VALID')\n",
    "    elif input_width == output_width:\n",
    "        return tf.nn.max_pool(x, ksize=[1, kernel_width, kernel_width, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def conv2d_relu(x, input_shape, output_shape, kernel_width = 5, strides=[1, 1, 1, 1]):\n",
    "    \"\"\"\n",
    "    Define a standard convolution layer with relu activation\n",
    "    \"\"\"\n",
    "    input_width = input_shape[0]\n",
    "    input_depth = input_shape[2]\n",
    "    output_width = output_shape[0]\n",
    "    kernel_depth = output_shape[2]\n",
    "    if output_width % 2:\n",
    "        raise Exception('Output shape is odd. Not supported at the moment')\n",
    "    elif  input_shape[0]!= input_shape[1] or output_shape[0]!= output_shape[1]:\n",
    "        raise Exception('Only square images supported')\n",
    "    if input_shape[0] == output_shape[0]:\n",
    "        padding = 'SAME'\n",
    "    elif input_shape[0] > output_shape[0]:\n",
    "        padding = 'VALID'\n",
    "        if input_width - output_width + 1 - kernel_width:\n",
    "            raise Exception(\n",
    "                'Kernel width of {} does not support {} - {} convolution'.format(\n",
    "                    kernel_width,input_width,output_width))\n",
    "    else:\n",
    "        raise Exception('Output size is larger than input')\n",
    "\n",
    "    conv_W = tf.Variable(tf.truncated_normal(shape=(kernel_width, kernel_width, input_depth, kernel_depth), mean = mu, stddev = sigma))\n",
    "    conv_b = tf.Variable(tf.zeros(kernel_depth))\n",
    "    conv = tf.nn.conv2d(x, conv_W, strides=strides, padding=padding) + conv_b\n",
    "    return tf.nn.relu(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNet(x, return_layer = None):        \n",
    "    # Convolutional layer #1\n",
    "    h1 = conv2d_relu(x, input_shape=(32,32,3),output_shape=(32,32,5), kernel_width=3)\n",
    "    h2 = max_pool(h1, input_shape = (32,32,5), output_shape=(32,32,5))\n",
    "    #h = tf.nn.dropout(h, 0.5)\n",
    "\n",
    "    # Convolutional layer #2\n",
    "    h3 = conv2d_relu(h2, input_shape=(32,32,5),output_shape=(32,32,10), kernel_width=3)\n",
    "    h4 = max_pool(h3, input_shape = (32,32,10), output_shape=(32,32,10))\n",
    "\n",
    "    # Convolutional layer #3\n",
    "    h5 = conv2d_relu(h4, input_shape=(32,32,10),output_shape=(32,32,20), kernel_width=3)\n",
    "    h6 = max_pool(h5, input_shape = (32,32,20), output_shape=(32,32,20))\n",
    "    h7 = tf.nn.dropout(h6, 0.5)\n",
    "\n",
    "    # Convolutional layer #4\n",
    "    h8 = conv2d_relu(h7, input_shape=(32,32,20), output_shape=(28,28,25), kernel_width=5)\n",
    "    h9 = max_pool(h8, input_shape = (28,28,25), output_shape=(14,14,25))\n",
    "\n",
    "    # Convolutional layer #5\n",
    "    h10 = conv2d_relu(h9, input_shape=(14,14,25), output_shape=(10,10,30), kernel_width=5)\n",
    "    h11 = max_pool(h10, input_shape = (10,10,30), output_shape=(5,5,30))\n",
    "    #h = tf.nn.dropout(h, 0.5)\n",
    "\n",
    "    # Flatten convolution\n",
    "    h12   = flatten_conv(h11, input_shape=(5,5,30), output_len=750)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    h13 = fc_relu(h12, input_len=750, output_len=43)\n",
    "    h14 = fc(h13, input_len=43, output_len=43)\n",
    "    if not return_layer:\n",
    "        return h14\n",
    "    elif return_layer == 1:\n",
    "        return h1\n",
    "    elif return_layer == 2:\n",
    "        return h2\n",
    "    elif return_layer == 3:\n",
    "        return h3\n",
    "    elif return_layer == 4:\n",
    "        return h4\n",
    "    elif return_layer == 5:\n",
    "        return h5\n",
    "    elif return_layer == 10:\n",
    "        return h10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "is_training = tf.placeholder(tf.bool, True)\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "rate = tf.placeholder(tf.float32, [])\n",
    "logits = KNet(x)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "layer1 = KNet(x)\n",
    "layer2 = KNet(x, return_layer=2)\n",
    "layer3 = KNet(x, return_layer=3)\n",
    "layer4 = KNet(x, return_layer=4)\n",
    "layer5 = KNet(x, return_layer=5)\n",
    "layer6 = KNet(x, return_layer=10)\n",
    "\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.950\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like the model has a 95 % acccuracy on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(X_data):\n",
    "    sess = tf.get_default_session()\n",
    "    num_examples = len(X_data)\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x = X_data[offset:offset+BATCH_SIZE]\n",
    "        l = sess.run(softmax, feed_dict={x: batch_x})\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c21ea3a0873f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_images/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_data_full_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "files = glob.glob('new_images/*')\n",
    "new_data_full_size = []\n",
    "new_data.append(img)\n",
    "for f in files:\n",
    "    img =cv2.imread(f)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    new_data_full_size.append(img)\n",
    "    rs_img = cv2.resize(img, (32, 32))\n",
    "    new_data.append(rs_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(12, 6), subplot_kw={'xticks': [], 'yticks': []})\n",
    "indices = range(len(new_data))\n",
    "for ax, index in zip(axes.flat, indices):\n",
    "    new_test_data = new_data_full_size[index]\n",
    "    ax.imshow(new_test_data)\n",
    "    ax.set_title('Image {}'.format(index))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resizing the downloaded images ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(12, 6), subplot_kw={'xticks': [], 'yticks': []})\n",
    "indices = range(len(new_data))\n",
    "for ax, index in zip(axes.flat, indices):\n",
    "    new_test_data = new_data[index]\n",
    "    ax.imshow(new_test_data)\n",
    "    ax.set_title('Image {}'.format(index))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(12, 6), subplot_kw={'xticks': [], 'yticks': []})\n",
    "indices = range(len(new_data))\n",
    "metadata = []\n",
    "for ax, index in zip(axes.flat, indices):\n",
    "    new_test_data = new_data[index]\n",
    "    ax.imshow(new_data_full_size[index])\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "        new_data_predictions = get_class([new_test_data])\n",
    "        p = new_data_predictions[0]\n",
    "        highest_logit = np.argmax(p)\n",
    "        predicted_class = sign_names['SignName'][highest_logit]\n",
    "        \n",
    "        top_5_indices = p.argsort()[-5:][::-1]\n",
    "        top_5_prob = p[top_5_indices]\n",
    "        top_5_names = sign_names['SignName'][top_5_indices]\n",
    "        metadata.append(\n",
    "        {\n",
    "            'img': new_data_full_size[index],\n",
    "            'predicted_class': predicted_class,\n",
    "            'top_5_prob': top_5_prob,\n",
    "            'top_5_names': top_5_names,\n",
    "        })\n",
    "    ax.set_title('{}'.format(predicted_class))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we got all 5 images (100 %) right !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_plot(m):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(221)\n",
    "    ax.barh(b,m['top_5_prob'])\n",
    "    plt.yticks(b,list(m['top_5_names']))\n",
    "    fig.add_subplot(222)\n",
    "    plt.imshow(m['img'])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_plot(metadata[0])\n",
    "get_plot(metadata[1])\n",
    "get_plot(metadata[2])\n",
    "get_plot(metadata[3])\n",
    "get_plot(metadata[4])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
